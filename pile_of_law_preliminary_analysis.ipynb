{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/carolyn-wang/pile-of-law_sentiment-analysis/blob/main/pile_of_law_preliminary_analysis.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VaGFTq8WmRaS"
      },
      "outputs": [],
      "source": [
        "!pip3 install datasets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UMSADo_XmFtw"
      },
      "outputs": [],
      "source": [
        "from datasets import load_dataset\n",
        "dataset_eoir = load_dataset(\"pile-of-law/pile-of-law\", 'eoir')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "m5HCXJZsmKLy"
      },
      "outputs": [],
      "source": [
        "dataset_eoir['train']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sbnGgvrtmdxl"
      },
      "outputs": [],
      "source": [
        "dataset_eoir['train']['text']"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.tokenize import sent_tokenize, word_tokenize\n",
        "import nltk\n",
        "nltk.download('punkt')"
      ],
      "metadata": {
        "id": "5c94wdzBpED9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "keywords = ['Mexico', 'China', 'Chinese', 'Pakistan', 'Muslim']"
      ],
      "metadata": {
        "id": "OoCnvE3BrySk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from collections import defaultdict\n",
        "\n",
        "keyword_sent = defaultdict(list)\n",
        "# dictionary such that each key is a keyword and each value is a list "
      ],
      "metadata": {
        "id": "yaNkHhSFhg6e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# clean dataset\n",
        "eoir_text_lst = dataset_eoir['train']['text']\n",
        "eoir_text_lst_cleaned = [', '.join(text.splitlines()) for text in eoir_text_lst]\n",
        "eoir_text_lst_cleaned"
      ],
      "metadata": {
        "id": "fC_wI7Oyuork"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.tokenize import word_tokenize\n",
        "\n",
        "eoir_sent_tokens = []\n",
        "for text in eoir_text_lst_cleaned:\n",
        "  for sentence in sent_tokenize(text):\n",
        "    for word in word_tokenize(sentence):\n",
        "      if word in keywords:\n",
        "        # print(word)\n",
        "        keyword_sent[word].append(sentence)\n"
      ],
      "metadata": {
        "id": "Nq8OUHHlqxwI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(keyword_sent['Mexico'])"
      ],
      "metadata": {
        "id": "0aFPpgyro_4l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip3 install transformers\n",
        "from transformers import pipeline"
      ],
      "metadata": {
        "id": "QxazlcDYcHdR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sentiment_analysis = pipeline(\"sentiment-analysis\",model=\"siebert/sentiment-roberta-large-english\")\n",
        "\n",
        "sentiment_dict = defaultdict(list)\n",
        "# for keyword in keywords:\n",
        "keyword = \"Mexico\"\n",
        "for i in range(len(keyword_sent[keyword])):\n",
        "  analysis = sentiment_analysis(keyword_sent[keyword][i])\n",
        "  sentiment_dict[keyword].extend(analysis)"
      ],
      "metadata": {
        "id": "PisL37tTnUzE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pos = []\n",
        "neg = []\n",
        "for d in sentiment_analysis:\n",
        "  if d['label'] == \"POSITIVE\": ## pawsitive\n",
        "    pos.append(d['score'])\n",
        "  else:\n",
        "    neg.append(d['score'])"
      ],
      "metadata": {
        "id": "-CkMZ9H3nkHo"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNJV57uy8qFoIFo8ujop7vb",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}